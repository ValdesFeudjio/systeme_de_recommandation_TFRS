{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dfrey/MyCode/blob/master/NN_based_recommender_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT8AyHRMNh41"
   },
   "source": [
    "# Basic recommender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f-reQ11gbLB"
   },
   "source": [
    "In this tutorial, we build a simple matrix factorization model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TFRS. We can use this model to recommend movies for a given user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "### Import TFRS\n",
    "\n",
    "First, install and import TFRS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow_recommenders in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.7.3)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_recommenders) (2.1.0)\n",
      "Requirement already satisfied: tensorflow>=2.9.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow_recommenders) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow>=2.9.0->tensorflow_recommenders) (2.18.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (57.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (2.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow>=2.9.0->tensorflow_recommenders) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.8)\n",
      "Requirement already satisfied: absl-py in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (0.1.9)\n",
      "Requirement already satisfied: etils>=1.6.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.12.2)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (4.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (2.0.2)\n",
      "Requirement already satisfied: promise in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-datasets) (6.1.1)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (19.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (2.32.3)\n",
      "Requirement already satisfied: simple_parsing in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (1.16.1)\n",
      "Requirement already satisfied: termcolor in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (2.5.0)\n",
      "Requirement already satisfied: toml in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (4.67.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-datasets) (1.17.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2025.3.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (4.12.2)\n",
      "Requirement already satisfied: zipp in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.21.0)\n",
      "Requirement already satisfied: einops in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (0.8.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2024.12.14)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dm-tree->tensorflow-datasets) (25.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from promise->tensorflow-datasets) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\lenovo pc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from simple_parsing->tensorflow-datasets) (0.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo pc\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->tensorflow-datasets) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCxQ1CZcO2wh"
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DvC9VVXOHlXn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\LENOVO PC\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\LENOVO PC\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  1.69s/ url]\n",
      "Extraction completed...: 100%|██████████| 23/23 [00:02<00:00, 10.51 file/s]\n",
      "Dl Size...: 100%|██████████| 4/4 [00:02<00:00,  1.82 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:02<00:00,  2.20s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to C:\\Users\\LENOVO PC\\tensorflow_datasets\\movielens\\100k-ratings\\0.1.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ratings_full = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "\n",
    "user_ids = ratings_full.map(lambda x: x[\"user_id\"])\n",
    "unique_user_ids = np.unique(list(tfds.as_numpy(user_ids)))\n",
    "\n",
    "movie_titles = ratings_full.map(lambda x: x[\"movie_title\"])\n",
    "unique_movie_titles = np.unique(list(tfds.as_numpy(movie_titles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgKXUeSO868N"
   },
   "source": [
    "> ### TODO\n",
    ">\n",
    "> Display the ten first examples to explore the list of available informations\n",
    ">\n",
    "> Usefull: `Dataset.take(count)`, `tfds.as_numpy()`, `tfds.as_dataframe()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DWXpgQVzHpwf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1664\n",
      "0.06372868912635615\n"
     ]
    }
   ],
   "source": [
    "print(unique_user_ids.size)\n",
    "print(unique_movie_titles.size)\n",
    "print(ratings_full.cardinality().numpy()/(unique_user_ids.size*unique_movie_titles.size))\n",
    "# TODO add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm-Ummuy93Tb"
   },
   "source": [
    "Restrict the dataset to used features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M-mxBYjdO5m7"
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = ratings_full.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "    \"timestamp\": x[\"timestamp\"],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXCQpH2LMSf0"
   },
   "source": [
    "Split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Oj5OYXLjMSqA"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "cached_train = train.shuffle(100_000).batch(2048)\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "### Define a model\n",
    "\n",
    "We can define a prediction model by inheriting from `tf.keras.Model` and implementing the `call` method.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Draw the model (you can draw it on a piece of paper and scan it, or take a picture of it, and include your picture in the zip file you submit. You should name your file either `[lastname1]-[lastname2]-modeldrawing.jpg/pdf/...` or `[firstname]-[lastname]-modeldrawing.jpg/pdf/...` depending on whether you worked in pairs or alone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XFalJDcOU4_d"
   },
   "outputs": [],
   "source": [
    "class DotRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.layers.Dot(axes=(1))\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
    "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    return self.ratings((user_embedding, movie_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9Y6hsvwWc7ZR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-0.00584763],\n",
       "       [-0.00333497]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Keras2\n",
    "#DotRankingModel()({\"user_id\": [\"42\",\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\", \"Strictly Ballroom (1992)\"]})\n",
    "\n",
    "# version for Keras 3\n",
    "user_ids_input = tf.constant([\"42\", \"42\"])\n",
    "movie_titles_input = tf.constant([\"One Flew Over the Cuckoo's Nest (1975)\", \"Strictly Ballroom (1992)\"])\n",
    "\n",
    "# Pass the tensors in the dict.\n",
    "DotRankingModel()({\"user_id\": user_ids_input, \"movie_title\": movie_titles_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnm3Monk-HbG"
   },
   "source": [
    "We can define a TFRS model by inheriting from `tfrs.Model` and implementing the `compute_loss` method.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Explain the role played by this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NXOntFjKdjaW"
   },
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_model: tf.keras.Model):\n",
    "    super().__init__()\n",
    "    self.ranking_model = rating_model\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(features)\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zca6clv-dWC"
   },
   "source": [
    "## Fit and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Y4jBtrYAU8LE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'movie_lens_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "TensorFlowTrainer._make_function.<locals>.one_step_on_data(data) should not modify its Python input arguments. Modifying a copy is allowed. The following parameter(s) were modified: data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Train and test\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m dot_model_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcached_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m dot_model_history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_root_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\LENOVO PC\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:129\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.multi_step_on_iterator\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmulti_step_on_iterator\u001b[39m(iterator):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mfrom_value(\n\u001b[1;32m--> 129\u001b[0m             \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m         )\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# the spec is set lazily during the tracing of `tf.while_loop`\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     empty_outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mOptional\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: TensorFlowTrainer._make_function.<locals>.one_step_on_data(data) should not modify its Python input arguments. Modifying a copy is allowed. The following parameter(s) were modified: data"
     ]
    }
   ],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(DotRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "dot_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = dot_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caiEkjUGfGVd"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8_8re05-taq"
   },
   "source": [
    "> ### TODO\n",
    ">\n",
    "> Comment the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### TODO\n",
    "> Can you make the model more accurate? How?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFyPZmqQl4Du"
   },
   "source": [
    "# More complex link between user's and item's representations\n",
    "\n",
    "Let replace the dot product between user's and item's representations by a fully connected layer of size 64, followed by a fully connected layer with a unique output.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> - Define the layer and adapt the `call` method\n",
    "> - Choose carefully the activation functions of the layers\n",
    ">\n",
    "> Useful: `tf.keras.Sequential`, `tf.keras.Dense`, `tf.concat`\n",
    "> \n",
    "> You can alo checkout the Tensorflow/Keras tutorial here https://www.tensorflow.org/guide/keras/sequential_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65LzTZe8mYbs"
   },
   "outputs": [],
   "source": [
    "class OneLayerRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = # TODO here\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
    "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    return self.ratings(# TODO here. Note keras.layer.Dot was taking a tuple as input, now your model takes something else. Useful tool: tf.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAx8po39mYj-"
   },
   "outputs": [],
   "source": [
    "OneLayerRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MomtyxVvmY0k"
   },
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(OneLayerRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "one_layer_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = one_layer_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCLZjF9Nok4S"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooZ4g25P0YSs"
   },
   "source": [
    "# Taking advantage of context features\n",
    "\n",
    "Let use timestamps of the ratings and movie titles to enrich the input of the model.\n",
    "\n",
    "Some preliminary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSeZJBJI4rUl"
   },
   "outputs": [],
   "source": [
    "timestamps = np.concatenate(list(ratings_full.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
    "\n",
    "max_timestamp = timestamps.max()\n",
    "min_timestamp = timestamps.min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xe9ghj84-ri"
   },
   "source": [
    "New user model.\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Draw and explain the role played by the components of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLcCzx-SzSBl"
   },
   "outputs": [],
   "source": [
    "class EnrichedRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Building blocks to compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.timestamp_embeddings = tf.keras.Sequential([\n",
    "        tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "        tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dimension),\n",
    "    ])\n",
    "\n",
    "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "    self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "    # Building blocks to compute embeddings for movies.\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
    "      max_tokens=max_tokens)\n",
    "\n",
    "    self.title_text_embeddings = tf.keras.Sequential([\n",
    "      self.title_vectorizer,\n",
    "      tf.keras.layers.Embedding(max_tokens, embedding_dimension, mask_zero=True),\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "    self.title_vectorizer.adapt(unique_movie_titles)\n",
    "\n",
    "\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    user_embedding = tf.concat([\n",
    "        self.user_embeddings(features[\"user_id\"]),\n",
    "        self.timestamp_embeddings(features[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(features[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)\n",
    "\n",
    "    movie_embedding = tf.concat([\n",
    "        self.movie_embeddings(features[\"movie_title\"]),\n",
    "        self.title_text_embeddings(features[\"movie_title\"]),\n",
    "    ], axis=1)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L9AP2s-1GCj"
   },
   "outputs": [],
   "source": [
    "EnrichedRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"], \"timestamp\":[879024327]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPrbGZZ22bzX"
   },
   "outputs": [],
   "source": [
    "# Create a retrieval model.\n",
    "model = MovieLensModel(EnrichedRankingModel())\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Train and test\n",
    "enriched_model_history = model.fit(\n",
    "    cached_train,\n",
    "    validation_data=cached_test,\n",
    "    validation_freq=1,\n",
    "    epochs=10,\n",
    "    verbose=1)\n",
    "\n",
    "test_accuracy = enriched_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
    "print(f\"RMSE: {test_accuracy:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqpESO5v2bzY"
   },
   "outputs": [],
   "source": [
    "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
    "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
    "plt.plot(enriched_model_history.history[\"val_root_mean_squared_error\"], label=\"enriched\")\n",
    "plt.title(\"Accuracy vs epoch\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"RMSE\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mdYyJSs7QPY"
   },
   "source": [
    "# More comple models\n",
    "\n",
    "\n",
    "\n",
    "> ### TODO\n",
    ">\n",
    "> Build and test more complex models:\n",
    "> - with more layers to link user's and item's representation\n",
    "> - integrating more contextual information: user's age, movie's genre, ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyVMhMsnRcN0"
   },
   "source": [
    "# Copyright\n",
    "\n",
    "Several section of this notebook originate from notebooks under the following copyright:\n",
    "\n",
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfR1i3oKRcOD"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
